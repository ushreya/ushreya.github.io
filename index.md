**Research Interests**
Behavioural Speech Signal Processing, Machine Learning Affective Multimedia, Sound Event Detection and Scene
Analysis, Automatic Speech Recognition

**Education**
National Tsing Hua University
-PhD in Department of Electrical Engineering

**Research Experience**

-Explicit modelling of verbal and non-verbal human sound events with conventional audio-visual context multimedia 
emotion recognition model by considering human events as an auxiliary yet another important modality.
-Developing and improving emotion recognition for induced emotions in movies by using Acoustic sound events cues 
and scene analysis.
-Considering and modelling the annotator’s perception and its affect on each other by cross-modal attention for fairness
in multimodal multimedia emotion recognition system.
-Building an architecture that takes advantage of integrating ASR network representations as additional input when 
training an acoustic sound event detector
-Code-switching ASR in low resource languages.
Performing sound event localization and detection by transfer learning from sound detection model to localization

**Cooperated Projects**

UT Dallas MSP	Lab - Chinese podcast database collection in emotion recognition context
C-Media	Electronics	Incorporation	(C-Media	Inc.)- Implement AI de-reverberation de-noise algorithm based on deep noise suppression
**Teaching Assistant Experience**
Introduction to Digital Signal Processing, NTHU
Introduction to Machine Learning, NTHU

**Internship**
Industrial techology Research Institute (ITRI) (June 2022 - now)

**Awards**
-NTHU International Student Scholarship (2022-2023)
-NTHU International Student Scholarship (2021-2022)
-NTHU International Student Scholarship (2020-2021)
-Merry Electroacoustic Paper Award 2020 (Finalists)
-NTHU International Student Scholarship (2019-2020)

**Skills**
-Languages Python, C++, MATLAB
-Libraries & toolkits Pytorch, Tensorflow, Kaldi, Docker

**Publications**

[1]	Woan-Shiuan Chien, Upadhyay Shreya G.*, Wei-Cheng Lin, Ya-Tse Wu, Bo-Hao Su, Carlos Busso, and Chi-Chun Lee. “Monologue versus Conversation: Differences in Emotion Perception and Acoustic Expressivity.” Proc. 10th International conference on affective computing and intelligent interactions (ACII), 2022. (Oral)
[2]	Upadhyay Shreya G., Bo-Hao Su, and Chi-Chun Lee. "Improving Induced Valence Recognition by Integrating Acoustic Sound Semantics in Movies." 30th European Signal Processing Conference (EUSIPCO), 2022. (Oral)
[3]	Upadhyay Shreya G., Bo-Hao Su, and Chi-Chun Lee. "Attentive Convolutional Recurrent Neural Network Using Phoneme-Level Acoustic Representation for Rare Sound Event Detection." Proc. Interspeech, 2020: 3102-3106. (Oral)
[4]	Upadhyay, Shreya G., and Kavita M. Kelkar. "Predicting Learner's Confidence from their Behaviour Using a Judgement Questionnaire." Fourth International Conference on Computing Communication Control and Automation (ICCUBEA). IEEE, 2018. (Oral)
[5]	"Accent Classification using Audio based Features." In 2018 Young Female Researchers in Speech Science and Technology workshop (Interspeech), 2018. (Poster) 
[6]	Accepted: "Arabic Dialect Identification using Staking Classifier." International Conference on Pattern Recognition and Artificial Intelligence, 2018.

